{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527cc24d",
   "metadata": {},
   "source": [
    "\n",
    "# ‚úàÔ∏è Airline Sentiment Review System (Jupyter Notebook)\n",
    "\n",
    "This notebook builds an **end‚Äëto‚Äëend sentiment analysis pipeline** for airline reviews/tweets using **Python, pandas, scikit‚Äëlearn, and TF‚ÄëIDF + Logistic Regression**.  \n",
    "It includes: data loading, cleaning, EDA, model training, evaluation, and exporting a reusable predictor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6579b",
   "metadata": {},
   "source": [
    "\n",
    "## üöÄ How to Use\n",
    "1. If you have the Kaggle dataset (e.g., `Tweets.csv` from *Twitter US Airline Sentiment*), place it next to this notebook and set `DATA_PATH` accordingly.  \n",
    "2. Otherwise, the notebook auto‚Äëgenerates a **small sample dataset** so you can run everything end‚Äëto‚Äëend.\n",
    "3. Run the cells **top to bottom**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2b2ad4",
   "metadata": {},
   "source": [
    "## üì¶ Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running locally and you don't have the packages, uncomment and run:\n",
    "# !pip install -U pandas scikit-learn matplotlib numpy joblib\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609df65",
   "metadata": {},
   "source": [
    "## üßæ Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84213bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set your dataset path here. If the file is not found, a tiny demo dataset is created.\n",
    "DATA_PATH = \"Tweets.csv\"  # Change this to your file (e.g., 'airline_tweets.csv')\n",
    "\n",
    "def load_or_create_demo(path):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"‚úÖ Loading dataset from: {path}\")\n",
    "        df = pd.read_csv(path)\n",
    "        # Try to auto-detect columns\n",
    "        possible_text_cols = [\"text\", \"review\", \"tweet\", \"content\", \"body\"]\n",
    "        possible_label_cols = [\"airline_sentiment\", \"sentiment\", \"label\", \"target\"]\n",
    "        text_col = next((c for c in possible_text_cols if c in df.columns), None)\n",
    "        label_col = next((c for c in possible_label_cols if c in df.columns), None)\n",
    "        if not text_col or not label_col:\n",
    "            raise ValueError(f\"Could not detect text/label columns. Found columns: {list(df.columns)}\\n\"\n",
    "                             \"Expected text column like one of ['text','review','tweet'] \"\n",
    "                             \"and label like ['airline_sentiment','sentiment','label'].\")\n",
    "        return df[[text_col, label_col]].rename(columns={text_col: \"text\", label_col: \"sentiment\"})\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Dataset not found. Creating a small demo dataset instead.\")\n",
    "        data = {\n",
    "            \"text\": [\n",
    "                \"Loved the flight, staff were amazing and seats were comfy\",\n",
    "                \"Terrible delay and rude service, never flying this airline again\",\n",
    "                \"Average experience, nothing special but it was on time\",\n",
    "                \"Great crew and smooth landing!\",\n",
    "                \"Lost my luggage and no one helped, extremely disappointed\",\n",
    "                \"Check-in was quick and easy, happy with the service\",\n",
    "                \"Flight canceled without proper notice, very bad management\",\n",
    "                \"Snacks were good and plane was clean\",\n",
    "                \"Long layover and no updates, frustrated\",\n",
    "                \"Pilot made clear announcements and cabin felt safe\"\n",
    "            ],\n",
    "            \"sentiment\": [\n",
    "                \"positive\", \"negative\", \"neutral\", \"positive\", \"negative\",\n",
    "                \"positive\", \"negative\", \"positive\", \"negative\", \"positive\"\n",
    "            ]\n",
    "        }\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "df = load_or_create_demo(DATA_PATH)\n",
    "print(df.head())\n",
    "print(\"\\nClass balance:\\n\", df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b93c7a",
   "metadata": {},
   "source": [
    "## üëÄ Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34460827",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic length features\n",
    "df['len'] = df['text'].str.len()\n",
    "print(\"Text length (chars):\\n\", df['len'].describe())\n",
    "\n",
    "# Plot class balance\n",
    "counts = df['sentiment'].value_counts()\n",
    "plt.figure()\n",
    "counts.plot(kind='bar', title='Class Balance')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee41be",
   "metadata": {},
   "source": [
    "## üßπ Preprocess & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We will rely on TfidfVectorizer's built-in cleaning (lowercasing, tokenization, and English stopwords).\n",
    "X = df['text'].astype(str).values\n",
    "y = df['sentiment'].astype(str).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y if len(np.unique(y)) > 1 else None\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22829c23",
   "metadata": {},
   "source": [
    "## ü§ñ Model: TF‚ÄëIDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5dd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=30000)),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, n_jobs=None))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred) if len(X_test) else None\n",
    "print(f\"Accuracy: {acc:.4f}\" if acc is not None else \"Accuracy: (demo set too small)\")\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, zero_division=0) if len(X_test) else \"N/A\")\n",
    "\n",
    "# Confusion Matrix\n",
    "if len(X_test):\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xticks(range(len(np.unique(y))), np.unique(y), rotation=45)\n",
    "    plt.yticks(range(len(np.unique(y))), np.unique(y))\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d89e93",
   "metadata": {},
   "source": [
    "## üîÅ Cross‚ÄëValidation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ffda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(df) >= 50 and len(np.unique(y)) > 1:\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring=\"accuracy\")\n",
    "    print(\"CV accuracy (5-fold):\", scores)\n",
    "    print(\"Mean ¬± Std:\", scores.mean(), \"¬±\", scores.std())\n",
    "else:\n",
    "    print(\"Dataset too small for meaningful CV; skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95658f15",
   "metadata": {},
   "source": [
    "## üíæ Save Model & Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_PATH = \"airline_sentiment_model.joblib\"\n",
    "joblib.dump(pipeline, MODEL_PATH)\n",
    "print(f\"‚úÖ Saved model to {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82998b",
   "metadata": {},
   "source": [
    "## üîÆ Try Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caa7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded = joblib.load(\"airline_sentiment_model.joblib\")\n",
    "samples = [\n",
    "    \"Flight was on time and staff were very friendly.\",\n",
    "    \"Worst experience ever, delayed and rude attendants.\",\n",
    "    \"It was okay, nothing great but not bad either.\"\n",
    "]\n",
    "preds = loaded.predict(samples)\n",
    "for s, p in zip(samples, preds):\n",
    "    print(f\"{p:8s} | {s}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e16fa",
   "metadata": {},
   "source": [
    "## üìù Project Summary (for forms/portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = {\n",
    "    \"project\": \"Airline Sentiment Review System\",\n",
    "    \"stack\": [\"Python\", \"pandas\", \"scikit-learn\", \"TF-IDF\", \"Logistic Regression\", \"matplotlib\"],\n",
    "    \"features\": [\n",
    "        \"Data loading with auto-detection of text/label columns\",\n",
    "        \"EDA (class balance, text lengths)\",\n",
    "        \"TF‚ÄëIDF + Logistic Regression pipeline\",\n",
    "        \"Evaluation (accuracy, classification report, confusion matrix)\",\n",
    "        \"Model export with joblib\",\n",
    "        \"Quick inference examples\"\n",
    "    ],\n",
    "    \"usage\": [\n",
    "        \"Set DATA_PATH to your dataset filename (e.g., 'Tweets.csv')\",\n",
    "        \"Run cells top-to-bottom\",\n",
    "        \"Use the saved model for production inference\"\n",
    "    ]\n",
    "}\n",
    "print(json.dumps(summary, indent=2))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
